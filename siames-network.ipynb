{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e84568-fce3-4ad0-b36a-1be0aa0c1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard dependencies\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9cafef-c7b2-4b16-86c0-776baf60dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 00:54:33.262060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-27 00:54:33.262097: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-27 00:54:33.263447: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-27 00:54:33.270889: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-27 00:54:34.296196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import tensorflow dependencies - Functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26df22e2-e7c3-4aea-ab42-dabc9488246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 00:54:35.470025: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:54:35.524773: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:54:35.525017: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f17e509-d4c7-4be2-a706-014acf9f6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "POS_PATH = os.path.join('data-siames', 'positive')\n",
    "NEG_PATH = os.path.join('data-siames', 'negative')\n",
    "ANC_PATH = os.path.join('data-siames', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fbbb78-bf50-4dc0-a194-463c21ff3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c70c76-e9f1-4d9e-8103-ea14d8574f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move LFW Images to the following repository data/negative\n",
    "for directory in os.listdir(NEG_PATH):\n",
    "    for file in os.listdir(os.path.join(NEG_PATH, directory)):\n",
    "        EX_PATH = os.path.join(NEG_PATH, directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea434d4c-f11e-441b-b9d0-5679bc95cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import uuid library to generate unique image names\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79e207-2379-496e-b982-30e710805518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    # Cut down frame to 250x250px\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    # Collect anchors \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the webcam\n",
    "cap.release()\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49503c6c-5c67-4b49-be3c-6ed396a016a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 22:05:43.345268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 22:05:43.345651: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 22:05:43.345903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 22:05:43.449431: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 22:05:43.449849: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 22:05:43.450170: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-23 22:05:43.450408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3504 MB memory:  -> device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2024-04-23 22:05:43.845787: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "anchor = tf.data.Dataset.list_files(\"./\"+ANC_PATH+'/*.jpg').take(300)\n",
    "\n",
    "positive = tf.data.Dataset.list_files(\"./\"+POS_PATH+'/*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(\"./\"+NEG_PATH+'/*.jpg').take(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f85052-a7bf-4269-80e8-bb4dee0d49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cce56c-20cc-4b15-9394-bb5934da0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    img = img / 255.0\n",
    "    \n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485c492-60a6-44a8-ae63-7217179f651f",
   "metadata": {},
   "source": [
    "Create Labele dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d59bbb-7cf2-4260-b63e-d9ec6b71c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (anchor, positive) => 1,1,1,1,1\n",
    "# (anchor, negative) => 0,0,0,0,0\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f07c302d-df28-45ce-bd46-b386258b2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633081a6-df1a-41f6-89ca-131ea3087d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b90b88c-2ebf-4a6f-b123-0822ca8defd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90df5c67-4190-4968-80d7-04e9d1ef418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "facec01f-f3bf-4ab2-8047-86702bf2d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3),name=\"input_image\")\n",
    "\n",
    "    #first conv\n",
    "    c1 = Conv2D(64,(10,10),activation=\"relu\")(inp)\n",
    "    m1 = MaxPooling2D(64,(2,2),padding=\"same\")(c1)\n",
    "\n",
    "    #second\n",
    "        # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "\n",
    "        # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5566c585-9f33-4b4c-99c8-e9cdc01f47f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 46, 46, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 20, 20, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 9, 9, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38960448 (148.62 MB)\n",
      "Trainable params: 38960448 (148.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding = make_embedding()\n",
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7137b10-cb35-4df1-a471-8ac18559ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Distance(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48c91915-69ac-4724-98f1-d5e6ef29b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_mode():\n",
    "     # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Distance()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d487e05-6cef-4d53-acc2-166d254263f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_img (InputLayer)      [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " validation_img (InputLayer  [(None, 100, 100, 3)]        0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)      (None, 4096)                 3896044   ['input_img[0][0]',           \n",
      "                                                          8          'validation_img[0][0]']      \n",
      "                                                                                                  \n",
      " distance (L1Distance)       (None, 4096)                 0         ['embedding[0][0]',           \n",
      "                                                                     'embedding[1][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    4097      ['distance[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38964545 (148.64 MB)\n",
      "Trainable params: 38964545 (148.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_mode()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec03df1-2388-452f-b1ad-47ef95356103",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80b76833-f7ed-4482-86b4-1ec0e580785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "    \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36fd7a29-209d-47bf-ad76-069697cb1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCH):\n",
    "    for epoch in range(1,EPOCH+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "\n",
    "             # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597af3f-88fd-45a3-b206-1e52683a4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 50\n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6eae5-9186-4edf-9e8b-9dee8e9151da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "siamese_model.save('siamesemodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "583941f8-322f-4605-9ed8-93a5589dc293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 00:59:18.761115: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:59:18.761465: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:59:18.761691: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:59:18.847030: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:59:18.847267: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:59:18.847461: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-27 00:59:18.847609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3472 MB memory:  -> device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Reload model \n",
    "model = tf.keras.models.load_model('siamesemodel.keras', \n",
    "                            custom_objects={'L1Distance':L1Distance, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c93c53c-6fed-4484-a6c7-bf6a4f6e76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model,detection_threshold, verfiy_threshold):\n",
    "        # Build results array\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('test-data', 'verification')):\n",
    "        input_img = preprocess(os.path.join('test-data', 'input' , 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('test-data', 'verification', image))\n",
    "        \n",
    "        # Make Predictions \n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "\n",
    "    # Detection Threshold: Metric above which a prediciton is considered positive \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    print(results)\n",
    "    # Verification Threshold: Proportion of positive predictions / total positive samples \n",
    "    print(len(os.listdir(os.path.join('test-data', 'verification'))))\n",
    "    verification = detection / len(os.listdir(os.path.join('test-data', 'verification'))) \n",
    "    verified = verification > verfiy_threshold\n",
    "    print(detection)\n",
    "    print(verification)\n",
    "    \n",
    "    \n",
    "    return results, verified\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1b9935-349a-4314-beda-1327fe2c5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a27f08c-992e-4217-8d62-9b096dc1ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d458b59e-30aa-41c5-b8dc-e9f263ee0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img_path):\n",
    "    open_cv_image = cv2.imread(img_path)\n",
    "    # rgb = pil_image.convert('RGB')\n",
    "    # open_cv_image = np.array(rgb)\n",
    "    # Convert RGB to BGR\n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "    gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    if len(faces) > 0:\n",
    "        # Assuming the first face is the target, you can modify this based on your requirements\n",
    "        x, y, w, h = faces[0]\n",
    "\n",
    "        # Calculate the new coordinates and dimensions for a 1:1 aspect ratio\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        size = int(max(w, h))\n",
    "        x_new = max(0, center_x - size // 2)\n",
    "        y_new = max(0, center_y - size // 2)\n",
    "\n",
    "        # Crop the head region with a 1:1 aspect ratio\n",
    "        cropped_head = open_cv_image[y_new:y_new+size, x_new:x_new+size]\n",
    "       \n",
    "        #cv2.imwrite(img_path, cropped_head)\n",
    "        # # Convert the cropped head back to PIL format\n",
    "        cropped_head_pil = Image.fromarray(cv2.cvtColor(cropped_head, cv2.COLOR_BGR2RGB))\n",
    "       \n",
    "        # # Save the cropped head image\n",
    "        cropped_head_pil.save(img_path)\n",
    "        print(\"Cropped head saved successfully.\")\n",
    "    else:\n",
    "        print(\"not valid face\")\n",
    "        \n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1108d591-0f53-494f-b941-d98f42742a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped head saved successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_detector(os.path.join('test-data', 'input', 'input_image.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8012a221-b16a-4f60-a1c1-157065665ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped head saved successfully.\n",
      "Cropped head saved successfully.\n",
      "not valid face\n",
      "not valid face\n",
      "Cropped head saved successfully.\n",
      "not valid face\n",
      "Cropped head saved successfully.\n",
      "not valid face\n",
      "not valid face\n",
      "not valid face\n",
      "not valid face\n",
      "not valid face\n",
      "not valid face\n",
      "not valid face\n",
      "not valid face\n",
      "Cropped head saved successfully.\n"
     ]
    }
   ],
   "source": [
    "for image in os.listdir(os.path.join('test-data', 'verification')):\n",
    "    face_detector(os.path.join('test-data', 'verification', image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b9cc2ef-9b74-4ac4-9a01-2007f42b95fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[array([[0.84685427]], dtype=float32), array([[0.74338996]], dtype=float32), array([[0.9855783]], dtype=float32), array([[0.33726758]], dtype=float32), array([[0.51073897]], dtype=float32), array([[0.96574956]], dtype=float32), array([[0.7099934]], dtype=float32), array([[0.00465539]], dtype=float32), array([[0.5876192]], dtype=float32), array([[0.73426634]], dtype=float32), array([[0.01897452]], dtype=float32), array([[0.91324824]], dtype=float32), array([[0.10491867]], dtype=float32), array([[0.88194233]], dtype=float32), array([[0.7936416]], dtype=float32), array([[0.7921631]], dtype=float32)]\n",
      "16\n",
      "12\n",
      "0.75\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "results, verified = verify(model, 0.5, 0.5)\n",
    "print(verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a5ee7-a283-4ddd-b8fc-2c7495a5f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped head saved successfully.\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "[array([[0.41061532]], dtype=float32), array([[0.38143983]], dtype=float32), array([[0.11740269]], dtype=float32)]\n",
      "3\n",
      "0\n",
      "0.0\n",
      "False\n",
      "Cropped head saved successfully.\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "[array([[0.32076934]], dtype=float32), array([[0.99981135]], dtype=float32), array([[0.9943685]], dtype=float32)]\n",
      "3\n",
      "2\n",
      "0.6666666666666666\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    cv2.imshow('Verification', frame)\n",
    "    \n",
    "    # Verification trigger\n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        # Save input image to application_data/input_image folder \n",
    "        cv2.imwrite(os.path.join('test-data', 'input', 'input_image.jpg'), frame)\n",
    "        face_detector(os.path.join('test-data', 'input', 'input_image.jpg'))\n",
    "        # Run verification\n",
    "        results, verified = verify(model, 0.5, 0.5)\n",
    "        print(verified)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
